{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting\n",
      "\n",
      "\n",
      "Loaded 1193514 word vectors.\n",
      "\n",
      "\n",
      "Making embedding index dict done in 155s \n",
      "\n",
      "\n",
      "\n",
      "Making Embedding matrix done in 0s \n",
      "\n",
      "\n",
      "\n",
      "Creating predictor model done in 201s \n",
      "\n",
      "<keras.engine.sequential.Sequential object at 0x00000204322F5358>\n",
      "Chutiya annotator tha :    row :  136\n",
      "Chutiya annotator tha :    row :  155\n",
      "Chutiya annotator tha :    row :  159\n",
      "Chutiya annotator tha :    row :  322\n",
      "Chutiya annotator tha :    row :  445\n",
      "Chutiya annotator tha :    row :  471\n",
      "Chutiya annotator tha :    row :  483\n",
      "Chutiya annotator tha :    row :  942\n",
      "\n",
      "\n",
      "Reading data done in 65s \n",
      "\n",
      "\n",
      "\n",
      "Making label vector done in 0s \n",
      "\n",
      "epochs :  1\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 195s 194ms/step - loss: 0.8438 - acc: 0.7438\n",
      "epochs :  2\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 28s 28ms/step - loss: 0.7063 - acc: 0.7567\n",
      "epochs :  3\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 28s 28ms/step - loss: 0.7027 - acc: 0.7567\n",
      "epochs :  4\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 26s 26ms/step - loss: 0.7036 - acc: 0.7567\n",
      "epochs :  5\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 29s 29ms/step - loss: 0.7003 - acc: 0.7567\n",
      "epochs :  6\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 31s 31ms/step - loss: 0.7036 - acc: 0.7567\n",
      "epochs :  7\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 34s 34ms/step - loss: 0.7058 - acc: 0.7567\n",
      "epochs :  8\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 30s 30ms/step - loss: 0.7034 - acc: 0.7567\n",
      "epochs :  9\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 34s 34ms/step - loss: 0.6994 - acc: 0.7567\n",
      "epochs :  10\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 36s 36ms/step - loss: 0.7023 - acc: 0.7567\n",
      "epochs :  11\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 36s 36ms/step - loss: 0.7030 - acc: 0.7567\n",
      "epochs :  12\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 38s 38ms/step - loss: 0.7030 - acc: 0.7567\n",
      "epochs :  13\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 26s 26ms/step - loss: 0.7028 - acc: 0.7567\n",
      "epochs :  14\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 28s 28ms/step - loss: 0.7019 - acc: 0.7567\n",
      "epochs :  15\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 28s 28ms/step - loss: 0.7018 - acc: 0.7567\n",
      "epochs :  16\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 29s 29ms/step - loss: 0.7014 - acc: 0.7567\n",
      "epochs :  17\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 28s 28ms/step - loss: 0.7028 - acc: 0.7567\n",
      "epochs :  18\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 25s 25ms/step - loss: 0.7003 - acc: 0.7567\n",
      "epochs :  19\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 27s 27ms/step - loss: 0.7019 - acc: 0.7567\n",
      "epochs :  20\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 25s 25ms/step - loss: 0.7018 - acc: 0.7567\n",
      "epochs :  21\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 28s 28ms/step - loss: 0.7025 - acc: 0.7567\n",
      "epochs :  22\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 32s 32ms/step - loss: 0.7030 - acc: 0.7567\n",
      "epochs :  23\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 39s 39ms/step - loss: 0.7032 - acc: 0.7567\n",
      "epochs :  24\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 32s 32ms/step - loss: 0.7009 - acc: 0.7567\n",
      "epochs :  25\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 25s 25ms/step - loss: 0.7017 - acc: 0.7567\n",
      "epochs :  26\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 26s 26ms/step - loss: 0.7014 - acc: 0.7567\n",
      "epochs :  27\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 32s 32ms/step - loss: 0.7037 - acc: 0.7567\n",
      "epochs :  28\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 42s 42ms/step - loss: 0.7011 - acc: 0.7567\n",
      "epochs :  29\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 35s 35ms/step - loss: 0.7017 - acc: 0.7567\n",
      "epochs :  30\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7027 - acc: 0.7567\n",
      "epochs :  31\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7024 - acc: 0.7567\n",
      "epochs :  32\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7015 - acc: 0.7567\n",
      "epochs :  33\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7014 - acc: 0.7567\n",
      "epochs :  34\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7020 - acc: 0.7567\n",
      "epochs :  35\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7023 - acc: 0.7567\n",
      "epochs :  36\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 22s 22ms/step - loss: 0.6998 - acc: 0.7567\n",
      "epochs :  37\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7013 - acc: 0.7567\n",
      "epochs :  38\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7005 - acc: 0.7567\n",
      "epochs :  39\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 22s 22ms/step - loss: 0.7039 - acc: 0.7567\n",
      "epochs :  40\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7009 - acc: 0.7567\n",
      "epochs :  41\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7046 - acc: 0.7567\n",
      "epochs :  42\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7008 - acc: 0.7567\n",
      "epochs :  43\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7016 - acc: 0.7567\n",
      "epochs :  44\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.6995 - acc: 0.7567\n",
      "epochs :  45\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7013 - acc: 0.7567\n",
      "epochs :  46\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 20ms/step - loss: 0.7021 - acc: 0.7567\n",
      "epochs :  47\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7014 - acc: 0.7567\n",
      "epochs :  48\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7019 - acc: 0.7567\n",
      "epochs :  49\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 20ms/step - loss: 0.7008 - acc: 0.7567\n",
      "epochs :  50\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7016 - acc: 0.7567\n",
      "epochs :  51\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 20s 20ms/step - loss: 0.7005 - acc: 0.7567\n",
      "epochs :  52\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 20ms/step - loss: 0.7018 - acc: 0.7567\n",
      "epochs :  53\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7023 - acc: 0.7567\n",
      "epochs :  54\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 20ms/step - loss: 0.7013 - acc: 0.7567\n",
      "epochs :  55\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7049 - acc: 0.7567\n",
      "epochs :  56\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7025 - acc: 0.7567\n",
      "epochs :  57\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7007 - acc: 0.7567\n",
      "epochs :  58\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7009 - acc: 0.7567\n",
      "epochs :  59\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7013 - acc: 0.7567\n",
      "epochs :  60\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7015 - acc: 0.7567\n",
      "epochs :  61\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 20ms/step - loss: 0.7033 - acc: 0.7567\n",
      "epochs :  62\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7026 - acc: 0.7567\n",
      "epochs :  63\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7012 - acc: 0.7567\n",
      "epochs :  64\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7028 - acc: 0.7567\n",
      "epochs :  65\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 20ms/step - loss: 0.7016 - acc: 0.7567\n",
      "epochs :  66\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7017 - acc: 0.7567\n",
      "epochs :  67\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 20s 20ms/step - loss: 0.7020 - acc: 0.7567\n",
      "epochs :  68\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7027 - acc: 0.7567\n",
      "epochs :  69\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003/1003 [==============================] - 21s 20ms/step - loss: 0.7014 - acc: 0.7567\n",
      "epochs :  70\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7014 - acc: 0.7567\n",
      "epochs :  71\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 20ms/step - loss: 0.7016 - acc: 0.7567\n",
      "epochs :  72\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 20ms/step - loss: 0.7009 - acc: 0.7567\n",
      "epochs :  73\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7013 - acc: 0.7567\n",
      "epochs :  74\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7014 - acc: 0.7567\n",
      "epochs :  75\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7011 - acc: 0.7567\n",
      "epochs :  76\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7002 - acc: 0.7567\n",
      "epochs :  77\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7018 - acc: 0.7567\n",
      "epochs :  78\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7015 - acc: 0.7567\n",
      "epochs :  79\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7013 - acc: 0.7567\n",
      "epochs :  80\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7020 - acc: 0.7567\n",
      "epochs :  81\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 20ms/step - loss: 0.7017 - acc: 0.7567\n",
      "epochs :  82\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 22s 22ms/step - loss: 0.7009 - acc: 0.7567\n",
      "epochs :  83\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 20ms/step - loss: 0.7002 - acc: 0.7567\n",
      "epochs :  84\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7025 - acc: 0.7567\n",
      "epochs :  85\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 22s 22ms/step - loss: 0.7006 - acc: 0.7567\n",
      "epochs :  86\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 35s 35ms/step - loss: 0.7030 - acc: 0.7567\n",
      "epochs :  87\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 37s 37ms/step - loss: 0.7019 - acc: 0.7567\n",
      "epochs :  88\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 32s 32ms/step - loss: 0.7015 - acc: 0.7567\n",
      "epochs :  89\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 22s 22ms/step - loss: 0.7008 - acc: 0.7567\n",
      "epochs :  90\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7014 - acc: 0.7567\n",
      "epochs :  91\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7020 - acc: 0.7567\n",
      "epochs :  92\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 22s 22ms/step - loss: 0.7029 - acc: 0.7567\n",
      "epochs :  93\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7019 - acc: 0.7567\n",
      "epochs :  94\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7010 - acc: 0.7567\n",
      "epochs :  95\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 21s 21ms/step - loss: 0.7008 - acc: 0.7567\n",
      "epochs :  96\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 22s 21ms/step - loss: 0.7017 - acc: 0.7567\n",
      "epochs :  97\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 22s 22ms/step - loss: 0.7010 - acc: 0.7567\n",
      "epochs :  98\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 22s 22ms/step - loss: 0.7015 - acc: 0.7567\n",
      "epochs :  99\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 22s 22ms/step - loss: 0.7028 - acc: 0.7567\n",
      "epochs :  100\n",
      "Epoch 1/1\n",
      "1003/1003 [==============================] - 22s 22ms/step - loss: 0.7017 - acc: 0.7567\n",
      "\n",
      "\n",
      "Fitting the model done in 2593s \n",
      "\n",
      "\n",
      "\n",
      "Reading unlabelled input done in 2060s \n",
      "\n",
      "100000/100000 [==============================] - 808s 8ms/step - ETA: 6:37 - ETA: 6:33\n",
      "\n",
      "\n",
      "Predicting done in 936s \n",
      "\n",
      "[[0.20029399 0.90274733 0.07877063]\n",
      " [0.20029406 0.90274715 0.07877064]\n",
      " [0.20029399 0.90274733 0.07877063]\n",
      " ...\n",
      " [0.20029402 0.90274745 0.07877063]\n",
      " [0.20029399 0.90274733 0.07877063]\n",
      " [0.20029405 0.90274733 0.07877066]]\n",
      "\n",
      "\n",
      "Weights are :\n",
      "\n",
      "\n",
      "[array([[ 0.00763757,  0.01070968,  0.01315841, ...,  0.01165953,\n",
      "        -0.00812889,  0.01181112],\n",
      "       [-0.085302  , -1.5077    , -0.36559   , ...,  0.22112   ,\n",
      "        -0.24556   ,  0.24827   ],\n",
      "       [ 0.86323   ,  0.031356  ,  0.10169   , ..., -0.28853   ,\n",
      "        -0.50833   , -0.31382   ],\n",
      "       ...,\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]], dtype=float32), array([[[-6.32111430e-02, -6.11472242e-02, -3.53968181e-02, ...,\n",
      "         -6.85649272e-03,  4.09370437e-02, -5.63813969e-02],\n",
      "        [-1.20287165e-01, -1.66290242e-03, -8.17732885e-02, ...,\n",
      "         -5.47811203e-02,  6.58986643e-02,  6.22066110e-02],\n",
      "        [ 2.88382871e-03, -7.47940689e-02,  2.29402892e-02, ...,\n",
      "         -6.84633851e-02,  2.66727023e-02,  7.74686858e-02],\n",
      "        ...,\n",
      "        [-8.61034840e-02, -5.11837229e-02, -9.75222811e-02, ...,\n",
      "         -1.36183212e-02, -9.81821269e-02,  1.61846783e-02],\n",
      "        [ 1.58265419e-02, -6.17810190e-02,  4.15809304e-02, ...,\n",
      "         -4.22630385e-02,  2.22924519e-02, -3.55034024e-02],\n",
      "        [ 2.69251764e-02, -9.20238048e-02,  3.41258245e-03, ...,\n",
      "         -1.66976440e-03,  8.34450126e-02, -4.91869599e-02]],\n",
      "\n",
      "       [[ 6.07888550e-02, -5.27042523e-02,  2.86425911e-02, ...,\n",
      "         -5.45966886e-02, -1.80464443e-02,  1.30102048e-02],\n",
      "        [-2.92313029e-03, -7.00040311e-02, -3.67052332e-02, ...,\n",
      "          5.54976612e-02,  2.45962087e-02,  6.65820837e-02],\n",
      "        [-2.15399098e-02,  4.41959053e-02, -4.08154614e-02, ...,\n",
      "         -1.35939540e-02, -9.25104972e-03, -1.35779446e-02],\n",
      "        ...,\n",
      "        [-1.00201659e-01, -4.39391397e-02, -1.04535781e-01, ...,\n",
      "          4.39283215e-02,  5.21081835e-02,  7.90146664e-02],\n",
      "        [ 5.61857559e-02, -9.56948772e-02, -1.49851302e-02, ...,\n",
      "         -1.99102256e-02, -1.06814973e-01,  1.92548684e-03],\n",
      "        [-4.14492078e-02,  6.00285232e-02,  5.48972376e-02, ...,\n",
      "          4.45174500e-02,  3.36403586e-02,  7.85882324e-02]],\n",
      "\n",
      "       [[ 3.49862613e-02, -5.87438531e-02,  1.72181241e-03, ...,\n",
      "          7.57579356e-02,  3.24192084e-02,  2.00439151e-02],\n",
      "        [ 1.63327102e-02, -2.25015599e-02, -9.76196211e-03, ...,\n",
      "          3.85722034e-02,  1.23511422e-02,  5.72571978e-02],\n",
      "        [-2.16596331e-02,  6.94712996e-02,  1.41791003e-02, ...,\n",
      "          7.14813024e-02, -6.68479130e-02, -1.03719383e-02],\n",
      "        ...,\n",
      "        [ 5.68932220e-02,  4.97490130e-02, -6.96368739e-02, ...,\n",
      "         -2.14676131e-02, -7.62656040e-04,  3.07394322e-02],\n",
      "        [ 4.36181994e-03, -5.28783873e-02,  3.10881273e-03, ...,\n",
      "         -2.22129263e-02, -1.22659072e-01, -6.27973005e-02],\n",
      "        [ 7.66682765e-03, -8.75117108e-02,  2.02241447e-02, ...,\n",
      "         -5.49420603e-02, -8.51356164e-02, -8.94832541e-04]],\n",
      "\n",
      "       [[ 1.93647500e-02,  1.86800566e-02, -9.49565545e-02, ...,\n",
      "          7.01283067e-02, -2.24455558e-02,  5.04997894e-02],\n",
      "        [-4.82593253e-02,  5.32605015e-02,  5.70039079e-02, ...,\n",
      "         -8.04502293e-02,  1.40029551e-05,  3.09682321e-02],\n",
      "        [-7.29096457e-02, -7.38386288e-02, -3.68104712e-03, ...,\n",
      "          8.14396888e-02, -6.44627735e-02,  5.53141348e-02],\n",
      "        ...,\n",
      "        [-1.19778059e-01,  3.70813124e-02,  1.17967920e-02, ...,\n",
      "          7.18117924e-03,  6.78870827e-02, -8.25896207e-03],\n",
      "        [-4.84916009e-02,  1.40770329e-02,  1.51472418e-02, ...,\n",
      "         -4.43871580e-02,  4.05093059e-02, -1.03923507e-01],\n",
      "        [ 7.81306475e-02,  6.04043528e-03,  3.88696194e-02, ...,\n",
      "          3.97813991e-02, -8.51299614e-02,  4.51763347e-02]],\n",
      "\n",
      "       [[-6.95637912e-02,  7.68631920e-02, -2.99058333e-02, ...,\n",
      "         -3.68792564e-02,  3.26791639e-03,  2.02283505e-02],\n",
      "        [ 2.23932490e-02, -1.15312980e-02,  2.60236976e-03, ...,\n",
      "          7.17362911e-02,  4.04755510e-02,  3.14834826e-02],\n",
      "        [ 1.95305236e-02, -8.73338431e-02, -5.62779270e-02, ...,\n",
      "          1.49742439e-02, -1.49942953e-02,  8.83335471e-02],\n",
      "        ...,\n",
      "        [-1.02034281e-03, -5.29411882e-02, -7.05624372e-02, ...,\n",
      "         -7.39805475e-02,  3.03893927e-02, -1.86311137e-02],\n",
      "        [-6.02264740e-02,  3.96672189e-02,  9.43042338e-02, ...,\n",
      "          1.99722294e-02,  1.04919463e-01, -2.22377405e-02],\n",
      "        [-6.91423938e-02, -2.32760943e-02, -1.04670681e-01, ...,\n",
      "         -7.45417252e-02, -8.35103821e-03,  8.39495733e-02]]],\n",
      "      dtype=float32), array([-0.00438973, -0.00506913, -0.01506464,  0.0118997 , -0.01581488,\n",
      "       -0.01162639,  0.02026118,  0.02153247, -0.02534353,  0.01097257,\n",
      "       -0.01550504, -0.01996434,  0.01412518,  0.01016615, -0.03282288,\n",
      "        0.00774586,  0.01465813, -0.01678148, -0.00691201,  0.02209971,\n",
      "       -0.00729523, -0.01432278, -0.0039952 , -0.01995044, -0.02450748,\n",
      "       -0.0107202 ,  0.02121351,  0.01930846,  0.01557018,  0.00868928,\n",
      "        0.00556268, -0.01309004,  0.00816331,  0.01161448,  0.0222506 ,\n",
      "       -0.00700262,  0.01295131, -0.00303065, -0.00474719, -0.01347593,\n",
      "       -0.02747171, -0.00489432, -0.00985245,  0.02187684, -0.01624073,\n",
      "        0.0196183 ,  0.00364665,  0.01322657,  0.02175529, -0.02065203,\n",
      "       -0.01684023, -0.02284908,  0.0165703 ,  0.01901834, -0.01200664,\n",
      "        0.010268  ,  0.00728959, -0.01992244,  0.00533731, -0.00346966,\n",
      "       -0.01617069,  0.01053926,  0.00482227,  0.01767764], dtype=float32), array([[-0.08687283,  0.00303084,  0.07085983, ...,  0.09153176,\n",
      "        -0.07587707,  0.0532415 ],\n",
      "       [-0.07233242,  0.02073335,  0.13455607, ...,  0.05246919,\n",
      "        -0.07825499,  0.01719471],\n",
      "       [ 0.03547505,  0.04761641, -0.09081452, ..., -0.04416429,\n",
      "        -0.07892727, -0.00224375],\n",
      "       ...,\n",
      "       [ 0.01664892,  0.0321597 , -0.08970974, ...,  0.04873137,\n",
      "        -0.10919793, -0.00878282],\n",
      "       [-0.12128166, -0.03762426, -0.12645304, ...,  0.01626124,\n",
      "         0.03122871,  0.00083623],\n",
      "       [ 0.04284402, -0.05163266,  0.09094638, ...,  0.11803354,\n",
      "         0.08501347,  0.05670256]], dtype=float32), array([[ 0.02500677, -0.09025242, -0.01417227, ..., -0.06585348,\n",
      "         0.06704006, -0.00817989],\n",
      "       [-0.08757095,  0.07907167,  0.04454725, ..., -0.02766904,\n",
      "        -0.06334162, -0.09470529],\n",
      "       [ 0.05060057,  0.0609133 , -0.12215709, ...,  0.02718662,\n",
      "         0.05830073,  0.02514221],\n",
      "       ...,\n",
      "       [ 0.03749018, -0.09932582,  0.02572286, ..., -0.03760127,\n",
      "        -0.04572561, -0.03165119],\n",
      "       [-0.04960232, -0.01556935, -0.07596712, ...,  0.01315831,\n",
      "        -0.01818793,  0.02082682],\n",
      "       [-0.04600774,  0.03229863, -0.02701998, ..., -0.01978267,\n",
      "        -0.06956038, -0.05184614]], dtype=float32), array([-2.47199810e-03,  1.61663024e-03, -5.56453597e-03,  3.97445522e-02,\n",
      "        3.66625423e-03,  2.26514949e-03,  4.50738147e-02,  3.42228226e-02,\n",
      "       -1.50416549e-02,  4.66149226e-02, -1.23509895e-02,  2.11660005e-02,\n",
      "       -8.15102644e-03, -7.47688767e-03,  3.90010029e-02,  1.97311342e-02,\n",
      "        1.12925693e-02, -1.78526081e-02,  5.46838716e-03, -4.88689840e-02,\n",
      "       -5.79372235e-03,  1.71849132e-02, -6.18519774e-03,  1.41984457e-03,\n",
      "        1.09575503e-03,  3.25426571e-02, -8.43785703e-03,  5.37150539e-02,\n",
      "       -8.11257679e-03, -7.48316385e-03, -1.86276119e-02, -3.83413173e-02,\n",
      "        1.17079085e-02,  6.07095007e-03,  3.13578057e-03, -3.40388482e-03,\n",
      "        1.49682928e-02, -8.53019208e-03, -1.54234730e-02, -9.82121564e-04,\n",
      "        4.55613285e-02, -1.21888705e-03, -1.98603682e-02,  2.31496282e-02,\n",
      "        4.34593670e-02,  1.09619442e-02, -1.25580729e-04, -2.63165930e-05,\n",
      "       -4.54115495e-03, -6.81907497e-03, -3.01591982e-03, -2.22896822e-02,\n",
      "        1.35244336e-02, -1.96168553e-02, -5.99630438e-02, -2.91420221e-02,\n",
      "        3.91039532e-03, -1.88461188e-02,  1.47020770e-02,  3.11270892e-03,\n",
      "        2.81656738e-02, -1.56346764e-02, -2.97399033e-02, -8.06792900e-02,\n",
      "       -1.27312364e-02,  1.03677269e-02, -1.14650456e-02,  2.80393995e-02,\n",
      "       -3.25519703e-02, -1.04467967e-03,  1.84614435e-02,  4.09324244e-02,\n",
      "       -4.31872867e-02,  5.72481379e-02, -3.49895805e-02, -2.13684477e-02,\n",
      "        1.50717003e-02, -8.25065281e-03,  1.75691452e-02, -1.22968843e-02,\n",
      "       -6.53104112e-03,  5.41318022e-02, -3.96942683e-02,  7.73144048e-03,\n",
      "       -3.45613225e-03,  3.66547778e-02,  5.32240868e-02,  3.21449377e-02,\n",
      "        1.01623936e-02, -9.25681461e-03, -1.65335406e-02,  4.94569838e-02,\n",
      "        3.23264897e-02,  2.45536235e-03,  4.62194346e-03,  5.10704354e-04,\n",
      "       -3.43301482e-02,  4.01088707e-02,  1.68135110e-02,  2.51565836e-02,\n",
      "        9.94446456e-01,  1.00315928e+00,  9.91808772e-01,  1.02848148e+00,\n",
      "        1.00620759e+00,  1.00285745e+00,  1.03482056e+00,  1.03000557e+00,\n",
      "        9.92740393e-01,  1.04683721e+00,  9.95698035e-01,  1.00988150e+00,\n",
      "        9.82977629e-01,  9.86349106e-01,  1.03405392e+00,  9.92870986e-01,\n",
      "        1.01147318e+00,  9.99315619e-01,  1.01042390e+00,  9.76976335e-01,\n",
      "        9.95944202e-01,  1.02764869e+00,  1.00506675e+00,  1.00906920e+00,\n",
      "        1.00506270e+00,  1.00727963e+00,  1.00005126e+00,  1.04306746e+00,\n",
      "        9.93244112e-01,  9.93885159e-01,  9.93998706e-01,  9.81145680e-01,\n",
      "        1.01880312e+00,  1.00193524e+00,  1.00928092e+00,  9.96812046e-01,\n",
      "        1.01367104e+00,  9.92019236e-01,  9.92959678e-01,  1.00766957e+00,\n",
      "        1.04408169e+00,  1.01132524e+00,  9.79283333e-01,  1.01650989e+00,\n",
      "        1.03977334e+00,  1.01093209e+00,  1.00604236e+00,  1.00106180e+00,\n",
      "        9.90356505e-01,  1.00123703e+00,  9.87173498e-01,  9.94987965e-01,\n",
      "        1.01374209e+00,  9.86745775e-01,  9.70209301e-01,  9.85233724e-01,\n",
      "        1.00063920e+00,  9.83877063e-01,  1.01318896e+00,  9.99788582e-01,\n",
      "        1.01800179e+00,  9.87684250e-01,  9.72818494e-01,  9.44912612e-01,\n",
      "        9.87216115e-01,  1.01226127e+00,  9.90546644e-01,  1.01837349e+00,\n",
      "        9.78855968e-01,  9.87978160e-01,  1.01080096e+00,  1.02407515e+00,\n",
      "        9.46033716e-01,  1.04868424e+00,  9.62000191e-01,  9.94966805e-01,\n",
      "        1.00100863e+00,  9.93177116e-01,  1.01229811e+00,  9.93099928e-01,\n",
      "        1.00106549e+00,  1.05154419e+00,  9.63679492e-01,  9.90124583e-01,\n",
      "        1.00273383e+00,  1.02803791e+00,  1.03776765e+00,  1.02689648e+00,\n",
      "        1.01098287e+00,  9.91920710e-01,  9.92723286e-01,  1.03875899e+00,\n",
      "        1.02046347e+00,  1.00421584e+00,  9.95476127e-01,  9.98302877e-01,\n",
      "        9.80773985e-01,  1.03320467e+00,  1.01872849e+00,  1.02141750e+00,\n",
      "       -2.05966197e-02, -2.36504693e-02,  1.91785824e-02,  2.40673758e-02,\n",
      "       -1.47458594e-02, -2.35218909e-02, -6.70664059e-03, -2.38238033e-02,\n",
      "       -1.03028528e-02,  2.90957652e-02, -2.17249971e-02, -3.47768702e-02,\n",
      "        6.64081890e-03,  1.31106088e-02,  2.40405966e-02,  2.57768892e-02,\n",
      "        2.19418406e-02,  2.25961171e-02, -2.00509485e-02, -2.14575761e-04,\n",
      "       -1.91752221e-02, -1.87317543e-02,  1.59144700e-02,  1.96961965e-02,\n",
      "       -1.89409610e-02, -2.25914493e-02, -1.65179204e-02,  2.79028174e-02,\n",
      "       -2.27494687e-02, -5.23560494e-03, -1.93037968e-02,  1.73875485e-02,\n",
      "       -1.59045141e-02,  2.13473625e-02, -2.08815318e-02,  1.72991138e-02,\n",
      "        3.35925519e-02,  1.21478003e-03, -1.78853236e-02,  1.41395759e-02,\n",
      "       -2.43385676e-02,  1.70849469e-02,  1.54722780e-02,  2.48175971e-02,\n",
      "        2.22088583e-02, -2.24639289e-02,  1.97192524e-02, -2.06373148e-02,\n",
      "       -1.30765215e-02, -1.50149232e-02,  8.38220119e-03,  8.14475305e-03,\n",
      "       -2.34740060e-02, -2.17433851e-02, -2.08162721e-02, -1.16306422e-02,\n",
      "       -2.04861257e-02,  2.12658290e-02,  2.30837930e-02,  2.02885345e-02,\n",
      "       -2.22649872e-02,  2.13498510e-02, -8.29483569e-03,  2.16678586e-02,\n",
      "       -1.98698174e-02, -2.09250469e-02,  1.62391569e-02, -2.24594623e-02,\n",
      "       -2.89480481e-03,  2.22058110e-02,  2.36772876e-02,  2.30456293e-02,\n",
      "       -1.16761914e-02, -2.64515448e-02, -6.12730952e-03,  1.75049882e-02,\n",
      "        2.52840649e-02, -5.49821788e-03,  2.12344248e-02,  9.10624512e-05,\n",
      "        1.45532126e-02, -3.50769572e-02, -1.53474640e-02, -2.79121175e-02,\n",
      "       -2.30837381e-03, -2.42003687e-02, -2.80734431e-02, -2.26211622e-02,\n",
      "       -2.10393146e-02, -1.73841547e-02,  1.80128012e-02, -2.85734963e-02,\n",
      "        2.19976548e-02, -1.75873563e-02, -2.19688714e-02,  2.00329162e-02,\n",
      "       -1.18743265e-02,  2.64703073e-02,  2.21994370e-02,  2.22748946e-02,\n",
      "       -2.46859919e-02, -1.38909407e-02, -1.42427133e-02,  4.94313911e-02,\n",
      "        1.95715930e-02, -3.24109336e-04,  3.24854292e-02,  4.17586938e-02,\n",
      "       -1.80744696e-02,  2.10960750e-02,  5.94805321e-03,  6.32902607e-04,\n",
      "       -2.07712892e-02, -3.24255042e-02,  3.17360051e-02, -2.71629095e-02,\n",
      "       -1.61729157e-02, -1.30591057e-02, -1.32071069e-02, -4.27485779e-02,\n",
      "       -2.39121392e-02,  1.20227803e-02, -3.97301763e-02,  4.77601658e-04,\n",
      "        6.35809675e-02,  1.94796198e-03, -1.03100818e-02,  3.69035415e-02,\n",
      "       -7.68221077e-03, -1.42879039e-02, -2.92777587e-02, -3.18803042e-02,\n",
      "        1.27773674e-04, -2.62016095e-02, -1.55920526e-02, -7.76958652e-03,\n",
      "        4.52851178e-03, -1.02797663e-02, -2.12950222e-02, -1.04225427e-02,\n",
      "        6.40454665e-02, -6.17677998e-03, -3.05849072e-02,  1.66213140e-02,\n",
      "        2.63794325e-02, -5.00493916e-03, -2.07015257e-02,  1.84919517e-02,\n",
      "       -5.99102676e-03, -1.93399284e-02, -1.34128919e-02, -2.16005929e-02,\n",
      "        6.12949533e-03, -2.74718497e-02, -4.27026860e-02, -7.46259615e-02,\n",
      "       -2.12625768e-02, -3.08710020e-02, -3.78002822e-02,  3.31107946e-03,\n",
      "        1.57564264e-02,  3.13231833e-02, -1.61830224e-02, -8.29655156e-02,\n",
      "       -2.92531028e-02,  6.72774715e-03, -1.79208573e-02,  1.51952878e-02,\n",
      "       -3.52828838e-02, -1.68577973e-02, -2.91437609e-03, -2.96332262e-04,\n",
      "       -4.65094931e-02,  2.15982143e-02, -3.87146510e-02, -2.30137873e-02,\n",
      "        4.41482896e-03, -1.26539394e-02,  6.04985189e-03, -4.00718078e-02,\n",
      "        6.01534592e-03,  2.92695723e-02,  1.98076405e-02, -3.69900255e-03,\n",
      "        4.16476920e-04,  2.49727461e-02,  2.51114015e-02,  2.46885195e-02,\n",
      "       -4.71753739e-02, -3.60216349e-02, -1.65030975e-02,  1.78197380e-02,\n",
      "        1.99473929e-02, -1.73767861e-02, -1.06985774e-02, -3.23470146e-03,\n",
      "       -3.64078246e-02,  1.23079475e-02,  1.34492023e-02,  1.84552849e-03],\n",
      "      dtype=float32), array([[ 0.13417614,  0.12465861, -0.01558284, ..., -0.08895785,\n",
      "         0.04293786,  0.07838763],\n",
      "       [ 0.11185618,  0.00379861,  0.00744182, ...,  0.1920213 ,\n",
      "        -0.12329137, -0.0171074 ],\n",
      "       [ 0.05564222,  0.02682542, -0.10338616, ...,  0.09053961,\n",
      "        -0.08116391, -0.09699296],\n",
      "       ...,\n",
      "       [ 0.18474276, -0.07815988,  0.0014728 , ..., -0.17412275,\n",
      "        -0.099948  , -0.07246447],\n",
      "       [ 0.10128841,  0.10280995,  0.04153464, ..., -0.0005218 ,\n",
      "        -0.0409385 ,  0.09366494],\n",
      "       [ 0.19717301,  0.05205405,  0.04808157, ...,  0.12221843,\n",
      "        -0.16088037, -0.0779916 ]], dtype=float32), array([[-1.73467081e-02, -9.54406261e-02,  1.20041154e-01, ...,\n",
      "        -1.78499788e-04,  1.65616617e-01, -6.40075281e-02],\n",
      "       [-1.24471754e-01, -4.10289764e-02,  3.11268792e-02, ...,\n",
      "        -1.72400307e-02,  6.94114193e-02,  1.42552587e-03],\n",
      "       [-1.22898608e-01,  2.90434882e-02,  9.73364711e-02, ...,\n",
      "         7.19409063e-02, -5.04868515e-02, -4.79616411e-02],\n",
      "       ...,\n",
      "       [ 3.68645303e-02, -7.58265108e-02,  1.21409819e-01, ...,\n",
      "         9.39851627e-02,  7.89852962e-02, -4.71710190e-02],\n",
      "       [-4.75526154e-02, -1.68623015e-01, -1.48071004e-02, ...,\n",
      "         5.10996245e-02,  2.19167396e-01,  7.31832907e-02],\n",
      "       [-1.54078320e-01, -9.56571326e-02,  4.25896309e-02, ...,\n",
      "         5.04041649e-02,  3.49704400e-02, -1.95034072e-01]], dtype=float32), array([ 5.62547930e-02,  1.37393386e-03,  1.26167210e-02,  1.50208641e-02,\n",
      "        3.25404517e-02,  4.19204384e-02,  4.86397836e-03,  3.16425376e-02,\n",
      "        4.09375280e-02, -6.46414682e-02,  2.07900628e-02, -5.04282257e-03,\n",
      "       -2.45369069e-04,  6.41914876e-03,  3.58003452e-02,  2.35113073e-02,\n",
      "       -1.61923375e-02,  2.11920310e-02,  5.50236041e-03,  1.16862648e-03,\n",
      "        4.73018214e-02,  2.51875147e-02,  4.49654162e-02,  5.88722490e-02,\n",
      "        4.32464182e-02,  4.66720909e-02,  1.38573041e-02,  6.51329607e-02,\n",
      "        1.44475950e-02, -1.25700729e-02, -2.99092662e-02, -3.90521586e-02,\n",
      "        1.05103731e+00,  9.81306016e-01,  1.02459049e+00,  1.01390076e+00,\n",
      "        1.03275967e+00,  1.02685916e+00,  1.01564229e+00,  1.02401364e+00,\n",
      "        1.03032076e+00,  9.47365105e-01,  1.02113426e+00,  1.00061989e+00,\n",
      "        9.82822299e-01,  1.03753746e+00,  1.04154181e+00,  1.02507102e+00,\n",
      "        9.67973948e-01,  1.02057838e+00,  1.03576040e+00,  9.89935160e-01,\n",
      "        1.03694022e+00,  1.01972151e+00,  1.03470945e+00,  1.04301155e+00,\n",
      "        1.04356027e+00,  1.04190862e+00,  1.01887226e+00,  1.05626297e+00,\n",
      "        1.01777422e+00,  9.77519155e-01,  9.66400862e-01,  9.50135112e-01,\n",
      "       -2.96357479e-02,  1.19787855e-02,  1.33344335e-02,  1.43645639e-02,\n",
      "        2.28422936e-02,  4.76866588e-02, -1.84355229e-02, -2.24925596e-02,\n",
      "       -2.63115317e-02, -1.65812820e-02, -2.05638241e-02,  7.21627241e-03,\n",
      "       -9.76235233e-03, -3.25190346e-03, -2.24232916e-02,  2.09714137e-02,\n",
      "       -3.19762826e-02, -1.42240878e-02, -1.89781338e-02, -2.88115535e-02,\n",
      "        2.82530524e-02, -2.03109384e-02,  2.75063757e-02,  2.94517968e-02,\n",
      "       -2.26296838e-02, -2.57267412e-02,  1.80974696e-02,  4.24074382e-02,\n",
      "       -2.01564413e-02, -1.76684894e-02, -4.86633275e-03,  1.89793259e-02,\n",
      "        2.73636095e-02, -2.61080917e-02,  2.66432064e-03, -2.84143426e-02,\n",
      "        3.74846831e-02,  1.04779275e-02,  5.08639924e-02,  5.61658628e-02,\n",
      "        1.82211231e-02, -5.85865304e-02, -1.61658265e-02,  1.40791843e-02,\n",
      "       -3.43769975e-02, -2.15550307e-02,  2.93167476e-02,  4.53205295e-02,\n",
      "       -2.88955923e-02,  2.54040235e-03,  5.11152558e-02, -1.01100542e-02,\n",
      "        5.56845497e-03, -1.43658351e-02,  1.12796454e-02,  6.18116297e-02,\n",
      "        7.28535652e-02,  2.49543339e-02, -1.08494861e-02,  9.06729326e-03,\n",
      "       -1.98573712e-02, -2.44422629e-02, -5.15654869e-02, -4.35910448e-02],\n",
      "      dtype=float32), array([[-0.09275543,  0.23664089,  0.11969322, ...,  0.17637998,\n",
      "        -0.25504056, -0.16607219],\n",
      "       [-0.25749558,  0.17628412, -0.19625536, ...,  0.2510317 ,\n",
      "         0.09418366, -0.1614371 ],\n",
      "       [ 0.21796109,  0.13802569,  0.05593487, ..., -0.14486186,\n",
      "         0.19003384,  0.13585491],\n",
      "       ...,\n",
      "       [ 0.214027  , -0.07637779,  0.17681393, ..., -0.06248154,\n",
      "         0.00240348, -0.12168578],\n",
      "       [-0.04799043,  0.10272577, -0.10360044, ..., -0.02623376,\n",
      "         0.23019263, -0.24536088],\n",
      "       [-0.18453112,  0.1758388 , -0.22369431, ...,  0.30750605,\n",
      "         0.07471391, -0.17294376]], dtype=float32), array([[-0.27546322, -0.19125298,  0.36047733, ...,  0.1333363 ,\n",
      "         0.25245538, -0.12151468],\n",
      "       [-0.09393319, -0.01503996,  0.04654947, ...,  0.23626593,\n",
      "        -0.06214663,  0.17442743],\n",
      "       [ 0.04233703, -0.08524089,  0.00946214, ..., -0.05709864,\n",
      "         0.1651685 ,  0.14541835],\n",
      "       ...,\n",
      "       [-0.09736387,  0.05185245,  0.11422904, ..., -0.19279905,\n",
      "        -0.24039756, -0.12593158],\n",
      "       [-0.01375472,  0.06247985, -0.12524602, ...,  0.02415862,\n",
      "         0.11006188, -0.01829123],\n",
      "       [-0.14017278, -0.03085116, -0.07356824, ...,  0.17246445,\n",
      "         0.02742514, -0.31032732]], dtype=float32), array([ 5.2788150e-02, -3.6020063e-02,  2.4929514e-02,  4.8867404e-02,\n",
      "        3.8169123e-02, -9.8814629e-02,  4.4849683e-02,  4.8926841e-02,\n",
      "        2.7126359e-02,  4.5863591e-02,  3.7804022e-02,  6.1750721e-02,\n",
      "        2.8816340e-02, -7.1144506e-02,  3.3701502e-02,  3.9345142e-02,\n",
      "        1.0522832e+00,  9.5507330e-01,  1.0122579e+00,  1.0589881e+00,\n",
      "        1.0395393e+00,  9.3169874e-01,  1.0297213e+00,  1.0580776e+00,\n",
      "        1.0351231e+00,  1.0470638e+00,  1.0460047e+00,  1.0356617e+00,\n",
      "        1.0444720e+00,  9.2665112e-01,  1.0136042e+00,  1.0293899e+00,\n",
      "       -3.1356804e-02, -4.6736933e-02,  4.6931859e-02,  1.3934383e-02,\n",
      "       -3.0751869e-02, -6.0813320e-03, -4.6774525e-02,  2.0834038e-02,\n",
      "       -3.5945110e-02, -2.7136758e-02, -1.2683286e-02, -3.5814591e-02,\n",
      "        2.5252976e-02,  2.8518310e-03, -5.0742026e-02, -5.0237745e-02,\n",
      "        3.1419966e-02, -3.8970269e-02, -5.9871486e-04,  3.6654674e-02,\n",
      "        4.0673535e-02, -6.7549482e-02, -1.3799345e-02,  4.2063601e-02,\n",
      "        4.3220636e-02,  4.4282172e-02,  1.0444880e-02,  1.9811286e-02,\n",
      "        3.7098608e-03, -8.6288154e-02,  8.9591211e-03,  9.1704682e-02],\n",
      "      dtype=float32), array([[-0.08819531, -0.13462256,  0.33119395],\n",
      "       [ 0.52987224,  0.0726139 , -0.13225366],\n",
      "       [ 0.31791875,  0.4726396 , -0.4160625 ],\n",
      "       [-0.31830615,  0.5468759 , -0.19493493],\n",
      "       [-0.21431997, -0.49346414,  0.09993266],\n",
      "       [ 0.20885508,  0.1895476 , -0.11385743],\n",
      "       [ 0.47130126,  0.47882575,  0.38399413],\n",
      "       [-0.166346  ,  0.54714745, -0.30083984],\n",
      "       [ 0.35507283,  0.08589025,  0.5792105 ],\n",
      "       [ 0.45677954,  0.25889534,  0.5667175 ],\n",
      "       [ 0.21054678, -0.4925446 , -0.07225425],\n",
      "       [-0.5044769 , -0.5671724 ,  0.5153972 ],\n",
      "       [-0.17389849,  0.04283301, -0.04707349],\n",
      "       [-0.24642925, -0.38202205,  0.01800048],\n",
      "       [ 0.5420512 , -0.55526584,  0.02426147],\n",
      "       [ 0.5797948 , -0.59983313,  0.5543958 ]], dtype=float32), array([-0.03403385,  0.05101708, -0.0480195 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, GRU\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from nltk.corpus import words, stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import csv\n",
    "import string\n",
    "import re\n",
    "\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "\tt0 = time.time()\n",
    "\tyield\n",
    "\tprint(\"\\n\\n\" + name + ' done in ' + str(round(time.time() - t0)) + 's \\n')\n",
    "\n",
    "print(\"\\n\\nStarting\\n\\n\")\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "allEnglishWords = words.words()\n",
    "allEnglishWords[:] = [x.lower() for x in allEnglishWords]\n",
    "vocabSize = len(allEnglishWords)\n",
    "tokenizer = Tokenizer(num_words=vocabSize)\n",
    "tokenised = tokenizer.fit_on_texts(allEnglishWords)\n",
    "\n",
    "def createPredictorModel():\n",
    "\tvocabSize = len(allEnglishWords)\n",
    "\ttokenizer = Tokenizer(num_words= vocabSize)\n",
    "\ttokenised = tokenizer.fit_on_texts(allEnglishWords)\n",
    "\tmodel = Sequential()\n",
    "\t\n",
    "\twith timer(\"Making embedding index dict\"):\n",
    "\t\tembeddings_index = dict()\n",
    "\t\tf = open('glove.twitter.27B/glove.twitter.27B.100d.txt', encoding=\"utf8\")\n",
    "\t\tfor line in f:\n",
    "\t\t\tvalues = line.split()\n",
    "\t\t\tword = values[0]\n",
    "\t\t\tcoefs = np.asarray(values[1:], dtype='float32')\n",
    "\t\t\tembeddings_index[word] = coefs\n",
    "\t\tf.close()\n",
    "\t\tprint('Loaded %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "\n",
    "\twith timer(\"Making Embedding matrix\"):\n",
    "\t\tembedding_matrix = np.zeros((vocabSize, 100))\n",
    "\t\tfor word, index in tokenizer.word_index.items():\n",
    "\t\t\tif index > vocabSize - 1:\n",
    "\t\t\t\tbreak\n",
    "\t\t\telse:\n",
    "\t\t\t\tembedding_vector = embeddings_index.get(word)\n",
    "\t\t\t\tif embedding_vector is not None:\n",
    "\t\t\t\t\tembedding_matrix[index] = embedding_vector\n",
    "\n",
    "\twith timer(\"Creating predictor model\"): \n",
    "\t\tmodel.add(Embedding(vocabSize, 100, input_length=180, weights=[embedding_matrix]))\n",
    "\t\tmodel.add(Dropout(0.2))\n",
    "\t\tmodel.add(Conv1D(64, 5, activation='relu'))\n",
    "\t\tmodel.add(MaxPooling1D(pool_size=4))\n",
    "\t\tmodel.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "\t\tmodel.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "\t\tmodel.add(LSTM(16, dropout=0.2, recurrent_dropout=0.2))\n",
    "\t\tmodel.add(Dense(3, activation='sigmoid'))\n",
    "\t\tmodel.compile(loss='categorical_crossentropy', optimizer='adam',    metrics=['accuracy'])\n",
    "\n",
    "\treturn model\n",
    "\n",
    "model = createPredictorModel()\n",
    "print(model)\n",
    "\n",
    "\n",
    "def clean(s):\n",
    "\ttransalator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\treturn s.translate(transalator)\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "\ttext = text.split(\",\")[-1]\n",
    "\ttext = clean(text).lower()\n",
    "\ttext = text.lower()\n",
    "\ttext = ' '.join([word for word in text.split()\n",
    "\t\t\t\t\t\t\t\t\tif word not in cachedStopWords])\n",
    "\ttext = ' '.join([word for word in text.split() if(not word.startswith(\n",
    "\t\t\"@\") and not word.startswith(\"http\") and not word.startswith(\"\\\\\"))])\n",
    "\ttext = ' '.join([word for word in text.split()\n",
    "\t\t\t\t\t\t\t\t\tif word in allEnglishWords])\n",
    "\t#text =  re.sub(\"[_]\",\"\",text)\n",
    "\t#remove tags\n",
    "\ttext = re.sub(\"&lt;/?.*?&gt;\", \" &lt;&gt; \", text)\n",
    "\t# remove special characters and digits\n",
    "\ttext = re.sub(\"(\\\\d|\\\\W)+\", \" \", text)\n",
    "\tif(text.startswith(\"rt \") or text.startswith(\" rt\")):\n",
    "\t\ttext = text[3:]\n",
    "\tif(text == \"rt\"):\n",
    "\t\ttext = \"\"\n",
    "\twhile(text != \"\" and text[0] == ' '):\n",
    "\t\ttext = text[1:]\n",
    "\treturn text\n",
    "\n",
    "\n",
    "with timer(\"Reading data\"):\n",
    "\t\tx = []\n",
    "\t\ty = []\n",
    "\t\tradical = []\n",
    "\t\tradicalOne = 0\n",
    "\t\tradicalZero = 0\n",
    "\t\tradicalTwo = 0\n",
    "\t\twith open(\"input.csv\", 'r', encoding=\"utf8\") as csvFile:\n",
    "\t\t\treader = csv.reader(csvFile)\n",
    "\t\t\tp = 0\n",
    "\t\t\tfor row in reader:\n",
    "\t\t\t\tif(p == 0):\n",
    "\t\t\t\t\tp = p + 1\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tif(len(row) >= 2):\n",
    "\t\t\t\t\ts = row[0]\n",
    "\t\t\t\t\tx.append(preprocess(s))\n",
    "\t\t\t\t\tif(row[2] != '0.0'):\n",
    "\t\t\t\t\t\t# radicalOne += 1\n",
    "\t\t\t\t\t\tif(row[2] != '1.0' and row[2] != '2.0'):\n",
    "\t\t\t\t\t\t\tprint(\"Chutiya annotator tha : \", row[2], \" row : \", p)\n",
    "\t\t\t\t\t\t\t# radicalOne -= 1\n",
    "\t\t\t\t\ts = 0\n",
    "\t\t\t\t\tif(row[2] == '1.0'):\n",
    "\t\t\t\t\t\tradicalOne += 1\n",
    "\t\t\t\t\t\ts = 1\n",
    "\t\t\t\t\tif(row[2] == '2.0'):\n",
    "\t\t\t\t\t\tradicalTwo += 1\n",
    "\t\t\t\t\t\ts = 2\n",
    "\t\t\t\t\tif(s == 0):\n",
    "\t\t\t\t\t\tradicalZero += 1\n",
    "\t\t\t\t\tradical.append(s)\n",
    "\t\t\t\tp = p + 1\n",
    "\t\tcsvFile.close\n",
    "\n",
    "X = []\n",
    "for t in x:\n",
    "\t\tt = re.sub(r'[^\\w\\s]', ' ', t)\n",
    "\t\tt = ' '.join([word for word in t.split() if word != \" \"])\n",
    "\t\tt = t.lower()\n",
    "\t\tt = ' '.join([word for word in t.split()\n",
    "\t\t\t\t\t\t\t\t\tif word not in cachedStopWords])\n",
    "\t\tX.append(t)\n",
    "\n",
    "tokenisedTest = tokenizer.texts_to_sequences(X)\n",
    "X_Test = sequence.pad_sequences(\n",
    "\ttokenisedTest, maxlen=180, padding='post')\n",
    "\n",
    "with timer(\"Making label vector\"):\n",
    "\t\tY = np.zeros([len(radical), 3], dtype=int)\n",
    "\t\tfor x in range(0, len(radical)):\n",
    "\t\t\t\tY[x, radical[x]] = 1\n",
    "\n",
    "radical = np.array(Y)\n",
    "with timer('Fitting the model'):\n",
    "\tepochs = 1\n",
    "\tprint(\"epochs : \", epochs)\n",
    "\tfitHistory = model.fit(\n",
    "\t\tX_Test, radical, epochs=1, batch_size=32)\n",
    "\ttrainingAccuracy = fitHistory.history['acc']\n",
    "\twhile(trainingAccuracy[0] < 0.99 and epochs < 100):\n",
    "\t\tepochs += 1\n",
    "\t\tprint(\"epochs : \", epochs)\n",
    "\t\tfitHistory = model.fit(\n",
    "\t\t\tX_Test, radical, epochs=1, batch_size=32)\n",
    "\t\ttrainingAccuracy = fitHistory.history['acc']\n",
    "\n",
    "\n",
    "with timer(\"Reading unlabelled input\"):\n",
    "\tunlabelledTweets = []\n",
    "\twith open('input2.csv', 'r', encoding = 'utf8') as csvFile:\n",
    "\t\treader = csv.reader(csvFile)\n",
    "\t\tfor row in reader:\n",
    "\t\t\tunlabelledTweets.append(preprocess(row[0]))\n",
    "\n",
    "with timer(\"Predicting\"):\n",
    "\ttokenisedForPredicting = tokenizer.texts_to_sequences(unlabelledTweets)\n",
    "\tX_prediction = sequence.pad_sequences(tokenisedForPredicting, maxlen = 180, padding = 'post')\n",
    "\tpredScores = model.predict(X_prediction, verbose = 1)\n",
    "\n",
    "# zeroes = 0\n",
    "# ones = 0\n",
    "# twos = 0\n",
    "\n",
    "# for x in predScores:\n",
    "# \tif(x == 0):\n",
    "# \t\tzeroes += 1\n",
    "# \telif(x == 1):\n",
    "# \t\tones += 1\n",
    "# \telse:\n",
    "# \t\ttwos += 1\n",
    "\n",
    "# print(\"Total unlabelled tweets : \", len(predScores), '\\nzeroes : ', zeroes, \"\\nones : \", ones, \"\\ntwos : \", twos)\n",
    "\n",
    "\n",
    "print(predScores)\n",
    "\n",
    "print(\"\\n\\nWeights are :\\n\\n\")\n",
    "print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(model.get_weights()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "test = numpy.asarray(model.get_weights())\n",
    "print(type(test))\n",
    "print(test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
